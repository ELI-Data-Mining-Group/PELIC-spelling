{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PELIC spelling validation\n",
    "\n",
    "**Authors: Joey Livorno, Sean Steinle, & Ben Naismith  \n",
    "Contact: bnaismith@pitt.edu**\n",
    "\n",
    "**Last updated:** Feb 11, 2021\n",
    "\n",
    "This notebook describes the validation of the automated spelling correction carried out in the [PELIC_spelling.ipynb](https://github.com/ELI-Data-Mining-Group/PELIC-spelling/blob/master/PELIC_spelling.ipynb) notebook. The original dataset is [the University of Pittsburgh English Language Institute Corpus (PELIC)](https://github.com/ELI-Data-Mining-Group/PELIC-dataset).\n",
    "\n",
    "In brief, manual checking of spelling is performed on a sample of PELIC and is then compared to the output of the automated spell checker. The results indicate that spell-checker is highly accurate in terms of the total tokens in PELIC, but conservative resulting in lower precision.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction](#1.-Introduction)\n",
    "2. [Initial setup](#2.-Initial-setup)\n",
    "3. [Preparing the data](#3.-Preparing-the-data)\n",
    "4. [Spell check comparison](#4.-Spell-check-comparison)\n",
    "5. [Data analysis](#Data-analysis)\n",
    "6. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "The [PELIC-spelling](https://github.com/ELI-Data-Mining-Group/PELIC-spelling) repository accompanies the main PELIC dataset and provides information and code about applying spelling correction to PELIC texts. This supplemental repository was created because the accuracy of learner spelling, and whether or not to correct misspellings, must be considered when using learner production data. Depending on the focus of the research, using uncorrected text may be preferable so as not to introduce potential error through an unnecessary level of text manipulation. In other instances, there might be a stronger justification for using corrected text so that spelling mistakes do not mask other salient linguistic features, i.e. what learners intended to write, or lessen the effectiveness of other automated processes. \n",
    "\n",
    "The spell-corrected version of PELIC data can be found in [`PELIC_compiled_spellcorrected.csv`](https://github.com/ELI-Data-Mining-Group/PELIC-spelling/blob/master/PELIC_compiled_spellcorrected.csv) which is a fork of the original [`PELIC_compiled.csv`](https://github.com/ELI-Data-Mining-Group/PELIC-dataset/blob/master/PELIC_compiled.csv). This spelling correction was performed through an automated process using the [SymSpell](https://pypi.org/project/symspellpy/) Python module (Garbe, 2020). The code and description of this process is in the [`PELIC_spelling.ipynb`](https://github.com/ELI-Data-Mining-Group/PELIC-spelling/blob/master/PELIC_spelling.ipynb) notebook.  \n",
    "\n",
    "In the current notebook, our goal is to validate this automated spelling process by comparing manual human spell checking against the automated spell checking for a sample of PELIC data. To do so, we assess the corrections made in `PELIC_compiled_spellchecked.csv` by randomly sampling 50 entries and comparing them to the manual corrections made by two expert annotators (and adjudicated by a third)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set preferred notebook format\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparing the Data \n",
    "\n",
    "In [`PELIC_compiled_spellcorrected.csv`](https://github.com/ELI-Data-Mining-Group/PELIC-spelling/blob/master/PELIC_compiled_spellcorrected.csv), the spelling changes are reflected in the column called `tok_lem_POS_corrected`. Each cell contains a list with a tuple for each token in the text. Each tuple has three parts: the token, the corresponding lemma, and its part of speech ([Penn Treebank tagset](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting the Sample\n",
    "\n",
    "**Note:** the `tok_lem_POS_corrected` value for an entry will be *NaN* if no corrections were made in the entry. If any token has been replaced with a corrected spelling, `tok_lem_POS_corrected` will contain a list of tuples for all tokens including both the correctly spelled ones and the misspelled ones.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>L1</th>\n",
       "      <th>gender</th>\n",
       "      <th>course_id</th>\n",
       "      <th>level_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>version</th>\n",
       "      <th>text_len</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tok_lem_POS</th>\n",
       "      <th>tok_lem_POS_corrected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eq0</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Male</td>\n",
       "      <td>149</td>\n",
       "      <td>4</td>\n",
       "      <td>g</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>177</td>\n",
       "      <td>I met my friend Nife while I was studying in a...</td>\n",
       "      <td>[I, met, my, friend, Nife, while, I, was, stud...</td>\n",
       "      <td>((I, i, PRP), (met, meet, VBD), (my, my, PRP$)...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>am8</td>\n",
       "      <td>Thai</td>\n",
       "      <td>Female</td>\n",
       "      <td>149</td>\n",
       "      <td>4</td>\n",
       "      <td>g</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>Ten years ago, I met a women on the train betw...</td>\n",
       "      <td>[Ten, years, ago, ,, I, met, a, women, on, the...</td>\n",
       "      <td>((Ten, ten, CD), (years, year, NNS), (ago, ago...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          anon_id      L1  gender course_id level_id class_id question_id  \\\n",
       "answer_id                                                                   \n",
       "1             eq0  Arabic    Male       149        4        g           5   \n",
       "2             am8    Thai  Female       149        4        g           5   \n",
       "\n",
       "          version  text_len  \\\n",
       "answer_id                     \n",
       "1               1       177   \n",
       "2               1       137   \n",
       "\n",
       "                                                        text  \\\n",
       "answer_id                                                      \n",
       "1          I met my friend Nife while I was studying in a...   \n",
       "2          Ten years ago, I met a women on the train betw...   \n",
       "\n",
       "                                                      tokens  \\\n",
       "answer_id                                                      \n",
       "1          [I, met, my, friend, Nife, while, I, was, stud...   \n",
       "2          [Ten, years, ago, ,, I, met, a, women, on, the...   \n",
       "\n",
       "                                                 tok_lem_POS  \\\n",
       "answer_id                                                      \n",
       "1          ((I, i, PRP), (met, meet, VBD), (my, my, PRP$)...   \n",
       "2          ((Ten, ten, CD), (years, year, NNS), (ago, ago...   \n",
       "\n",
       "          tok_lem_POS_corrected  \n",
       "answer_id                        \n",
       "1                           NaN  \n",
       "2                           NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in PELIC_compiled.csv\n",
    "\n",
    "pelic_df = pd.read_csv(\"../PELIC-spelling/PELIC_compiled_spellcorrected.csv\", index_col = 'answer_id', # answer_id is unique\n",
    "                      dtype = {'level_id':'object','question_id':'object','version':'object','course_id':'object'}, # str not ints\n",
    "                               converters={'tokens':literal_eval,'tok_lem_POS':literal_eval}) # read in as lists\n",
    "pelic_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the sample we first limit the search to only entries that have at least one corrected spelling mistake. Potential texts are also filtered to those with a text length greater than 50. The sample is seeded to ensure it can be reproduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>L1</th>\n",
       "      <th>gender</th>\n",
       "      <th>course_id</th>\n",
       "      <th>level_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>version</th>\n",
       "      <th>text_len</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tok_lem_POS</th>\n",
       "      <th>tok_lem_POS_corrected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23739</th>\n",
       "      <td>bv1</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Male</td>\n",
       "      <td>479</td>\n",
       "      <td>4</td>\n",
       "      <td>g</td>\n",
       "      <td>3074</td>\n",
       "      <td>2</td>\n",
       "      <td>323</td>\n",
       "      <td>I was sleeping when my cell phone rang. Then I...</td>\n",
       "      <td>[I, was, sleeping, when, my, cell, phone, rang...</td>\n",
       "      <td>((I, i, PRP), (was, be, VBD), (sleeping, sleep...</td>\n",
       "      <td>[('i', 'i', 'PRP'), ('was', 'be', 'VBD'), ('sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23488</th>\n",
       "      <td>fd6</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Female</td>\n",
       "      <td>504</td>\n",
       "      <td>5</td>\n",
       "      <td>g</td>\n",
       "      <td>3052</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>I had an experience that taught me intuitive d...</td>\n",
       "      <td>[I, had, an, experience, that, taught, me, int...</td>\n",
       "      <td>((I, i, PRP), (had, have, VBD), (an, a, DT), (...</td>\n",
       "      <td>[('i', 'i', 'PRP'), ('had', 'have', 'VBD'), ('...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          anon_id      L1  gender course_id level_id class_id question_id  \\\n",
       "answer_id                                                                   \n",
       "23739         bv1  Arabic    Male       479        4        g        3074   \n",
       "23488         fd6  Korean  Female       504        5        g        3052   \n",
       "\n",
       "          version  text_len  \\\n",
       "answer_id                     \n",
       "23739           2       323   \n",
       "23488           1       169   \n",
       "\n",
       "                                                        text  \\\n",
       "answer_id                                                      \n",
       "23739      I was sleeping when my cell phone rang. Then I...   \n",
       "23488      I had an experience that taught me intuitive d...   \n",
       "\n",
       "                                                      tokens  \\\n",
       "answer_id                                                      \n",
       "23739      [I, was, sleeping, when, my, cell, phone, rang...   \n",
       "23488      [I, had, an, experience, that, taught, me, int...   \n",
       "\n",
       "                                                 tok_lem_POS  \\\n",
       "answer_id                                                      \n",
       "23739      ((I, i, PRP), (was, be, VBD), (sleeping, sleep...   \n",
       "23488      ((I, i, PRP), (had, have, VBD), (an, a, DT), (...   \n",
       "\n",
       "                                       tok_lem_POS_corrected  \n",
       "answer_id                                                     \n",
       "23739      [('i', 'i', 'PRP'), ('was', 'be', 'VBD'), ('sl...  \n",
       "23488      [('i', 'i', 'PRP'), ('had', 'have', 'VBD'), ('...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly sample 50 entries\n",
    "\n",
    "pelic_df = pelic_df[pelic_df['tok_lem_POS_corrected'].notnull()]\n",
    "sample_df = pelic_df[pelic_df['text_len'] >= 50].sample(n=50, random_state=2)\n",
    "sample_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_len</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tok_lem_POS_corrected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23739</th>\n",
       "      <td>323</td>\n",
       "      <td>I was sleeping when my cell phone rang. Then I...</td>\n",
       "      <td>[i, was, sleeping, when, my, cell, phone, rang...</td>\n",
       "      <td>[('i', 'i', 'PRP'), ('was', 'be', 'VBD'), ('sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23488</th>\n",
       "      <td>169</td>\n",
       "      <td>I had an experience that taught me intuitive d...</td>\n",
       "      <td>[i, had, an, experience, that, taught, me, int...</td>\n",
       "      <td>[('i', 'i', 'PRP'), ('had', 'have', 'VBD'), ('...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16214</th>\n",
       "      <td>159</td>\n",
       "      <td>The most interesting experience I have ever ha...</td>\n",
       "      <td>[the, most, interesting, experience, i, have, ...</td>\n",
       "      <td>[('the', 'the', 'DT'), ('most', 'most', 'RBS')...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11926</th>\n",
       "      <td>119</td>\n",
       "      <td>When I was a five years old. I had a very pre...</td>\n",
       "      <td>[when, i, was, a, five, years, old, ., i, had,...</td>\n",
       "      <td>[('when', 'when', 'WRB'), ('i', 'i', 'PRP'), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38157</th>\n",
       "      <td>128</td>\n",
       "      <td>Traveling makes me happy. I am really like to ...</td>\n",
       "      <td>[traveling, makes, me, happy, ., i, am, really...</td>\n",
       "      <td>[('traveling', 'travel', 'VBG'), ('makes', 'ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text_len                                               text  \\\n",
       "answer_id                                                                \n",
       "23739           323  I was sleeping when my cell phone rang. Then I...   \n",
       "23488           169  I had an experience that taught me intuitive d...   \n",
       "16214           159  The most interesting experience I have ever ha...   \n",
       "11926           119   When I was a five years old. I had a very pre...   \n",
       "38157           128  Traveling makes me happy. I am really like to ...   \n",
       "\n",
       "                                                      tokens  \\\n",
       "answer_id                                                      \n",
       "23739      [i, was, sleeping, when, my, cell, phone, rang...   \n",
       "23488      [i, had, an, experience, that, taught, me, int...   \n",
       "16214      [the, most, interesting, experience, i, have, ...   \n",
       "11926      [when, i, was, a, five, years, old, ., i, had,...   \n",
       "38157      [traveling, makes, me, happy, ., i, am, really...   \n",
       "\n",
       "                                       tok_lem_POS_corrected  \n",
       "answer_id                                                     \n",
       "23739      [('i', 'i', 'PRP'), ('was', 'be', 'VBD'), ('sl...  \n",
       "23488      [('i', 'i', 'PRP'), ('had', 'have', 'VBD'), ('...  \n",
       "16214      [('the', 'the', 'DT'), ('most', 'most', 'RBS')...  \n",
       "11926      [('when', 'when', 'WRB'), ('i', 'i', 'PRP'), (...  \n",
       "38157      [('traveling', 'travel', 'VBG'), ('makes', 'ma...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create subset of dataframe that includes only relevant columns\n",
    "\n",
    "sample_df = sample_df[['text_len', 'text', 'tokens', 'tok_lem_POS_corrected']]\n",
    "sample_df['tokens'] = sample_df.tokens.map(lambda x: [w.lower() for w in x]) #lowercase for easier comparison\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out dataframe to csv for annotators to check independently\n",
    "\n",
    "sample_df.to_csv('sample_blank.csv', encoding='utf-8', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the annotated samples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the annotated samples, each annotator created a columns duplicating the original `annotator2_df` called `checked`.  In this column, misspelled tokens were replaced with their correct spellings.  \n",
    "\n",
    "**Note:** Annotators were instructed to only correct non-words, i.e., real words which may not have been intended were left as is, e.g., _two_ and _tow_. Although in some cases the intended word is clear, in learner language there are often ambiguities as well, so a consistent and simple algorithim was adopted to avoid having to guess what the learner may have intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tok_lem_POS_corrected</th>\n",
       "      <th>checked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23739</th>\n",
       "      <td>I was sleeping when my cell phone rang. Then I...</td>\n",
       "      <td>[I, was, sleeping, when, my, cell, phone, rang...</td>\n",
       "      <td>[(i, i, PRP), (was, be, VBD), (sleeping, sleep...</td>\n",
       "      <td>[I, was, sleeping, when, my, cell, phone, rang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23488</th>\n",
       "      <td>I had an experience that taught me intuitive d...</td>\n",
       "      <td>[I, had, an, experience, that, taught, me, int...</td>\n",
       "      <td>[(i, i, PRP), (had, have, VBD), (an, a, DT), (...</td>\n",
       "      <td>[I, had, an, experience, that, taught, me, int...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text  \\\n",
       "answer_id                                                      \n",
       "23739      I was sleeping when my cell phone rang. Then I...   \n",
       "23488      I had an experience that taught me intuitive d...   \n",
       "\n",
       "                                                      tokens  \\\n",
       "answer_id                                                      \n",
       "23739      [I, was, sleeping, when, my, cell, phone, rang...   \n",
       "23488      [I, had, an, experience, that, taught, me, int...   \n",
       "\n",
       "                                       tok_lem_POS_corrected  \\\n",
       "answer_id                                                      \n",
       "23739      [(i, i, PRP), (was, be, VBD), (sleeping, sleep...   \n",
       "23488      [(i, i, PRP), (had, have, VBD), (an, a, DT), (...   \n",
       "\n",
       "                                                     checked  \n",
       "answer_id                                                     \n",
       "23739      [I, was, sleeping, when, my, cell, phone, rang...  \n",
       "23488      [I, had, an, experience, that, taught, me, int...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tok_lem_POS_corrected</th>\n",
       "      <th>checked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23739</th>\n",
       "      <td>I was sleeping when my cell phone rang. Then I...</td>\n",
       "      <td>[I, was, sleeping, when, my, cell, phone, rang...</td>\n",
       "      <td>[(i, i, PRP), (was, be, VBD), (sleeping, sleep...</td>\n",
       "      <td>[I, was, sleeping, when, my, cell, phone, rang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23488</th>\n",
       "      <td>I had an experience that taught me intuitive d...</td>\n",
       "      <td>[I, had, an, experience, that, taught, me, int...</td>\n",
       "      <td>[(i, i, PRP), (had, have, VBD), (an, a, DT), (...</td>\n",
       "      <td>[I, had, an, experience, that, taught, me, int...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text  \\\n",
       "answer_id                                                      \n",
       "23739      I was sleeping when my cell phone rang. Then I...   \n",
       "23488      I had an experience that taught me intuitive d...   \n",
       "\n",
       "                                                      tokens  \\\n",
       "answer_id                                                      \n",
       "23739      [I, was, sleeping, when, my, cell, phone, rang...   \n",
       "23488      [I, had, an, experience, that, taught, me, int...   \n",
       "\n",
       "                                       tok_lem_POS_corrected  \\\n",
       "answer_id                                                      \n",
       "23739      [(i, i, PRP), (was, be, VBD), (sleeping, sleep...   \n",
       "23488      [(i, i, PRP), (had, have, VBD), (an, a, DT), (...   \n",
       "\n",
       "                                                     checked  \n",
       "answer_id                                                     \n",
       "23739      [I, was, sleeping, when, my, cell, phone, rang...  \n",
       "23488      [I, had, an, experience, that, taught, me, int...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read samples from annotators 1 and 2\n",
    "\n",
    "annotator1_df = pd.read_csv(\"annotator1.csv\", index_col = 'answer_id',\n",
    "                            converters={'tokens':literal_eval,'tok_lem_POS':literal_eval,'tok_lem_POS_corrected':literal_eval,'checked':literal_eval})\n",
    "annotator1_df.head(2)\n",
    "\n",
    "annotator2_df = pd.read_csv(\"annotator2.csv\", index_col = 'answer_id',\n",
    "                            converters={'tokens':literal_eval,'tok_lem_POS':literal_eval,'tok_lem_POS_corrected':literal_eval,'checked':literal_eval})\n",
    "annotator2_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotator agreement rates\n",
    "\n",
    "To assess inter-annotator reliability, we calculate simple agreement rates, which is frequently used in Natural Language Processing. The alternative, Kappa, is not used because it may underestimate the agreement of a rare category, in this case misspelled words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tok_lem_POS_corrected</th>\n",
       "      <th>checked</th>\n",
       "      <th>enumerated_checked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23739</th>\n",
       "      <td>I was sleeping when my cell phone rang. Then I...</td>\n",
       "      <td>[I, was, sleeping, when, my, cell, phone, rang...</td>\n",
       "      <td>[(i, i, PRP), (was, be, VBD), (sleeping, sleep...</td>\n",
       "      <td>[I, was, sleeping, when, my, cell, phone, rang...</td>\n",
       "      <td>[(0, I), (1, was), (2, sleeping), (3, when), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23488</th>\n",
       "      <td>I had an experience that taught me intuitive d...</td>\n",
       "      <td>[I, had, an, experience, that, taught, me, int...</td>\n",
       "      <td>[(i, i, PRP), (had, have, VBD), (an, a, DT), (...</td>\n",
       "      <td>[I, had, an, experience, that, taught, me, int...</td>\n",
       "      <td>[(0, I), (1, had), (2, an), (3, experience), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text  \\\n",
       "answer_id                                                      \n",
       "23739      I was sleeping when my cell phone rang. Then I...   \n",
       "23488      I had an experience that taught me intuitive d...   \n",
       "\n",
       "                                                      tokens  \\\n",
       "answer_id                                                      \n",
       "23739      [I, was, sleeping, when, my, cell, phone, rang...   \n",
       "23488      [I, had, an, experience, that, taught, me, int...   \n",
       "\n",
       "                                       tok_lem_POS_corrected  \\\n",
       "answer_id                                                      \n",
       "23739      [(i, i, PRP), (was, be, VBD), (sleeping, sleep...   \n",
       "23488      [(i, i, PRP), (had, have, VBD), (an, a, DT), (...   \n",
       "\n",
       "                                                     checked  \\\n",
       "answer_id                                                      \n",
       "23739      [I, was, sleeping, when, my, cell, phone, rang...   \n",
       "23488      [I, had, an, experience, that, taught, me, int...   \n",
       "\n",
       "                                          enumerated_checked  \n",
       "answer_id                                                     \n",
       "23739      [(0, I), (1, was), (2, sleeping), (3, when), (...  \n",
       "23488      [(0, I), (1, had), (2, an), (3, experience), (...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a column with enumerated checked texts\n",
    "\n",
    "annotator1_df['enumerated_checked'] = annotator1_df.checked.apply(enumerate).apply(list)\n",
    "annotator2_df['enumerated_checked'] = annotator2_df.checked.apply(enumerate).apply(list)\n",
    "annotator1_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of annotator tokens tokens to compare\n",
    "\n",
    "annotator1_toks = [x for y in annotator1_df.enumerated_checked.to_list() for x in y] # Make a list of tokens and flatten\n",
    "annotator2_toks = [x for y in annotator2_df.enumerated_checked.to_list() for x in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11595"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "11595"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate total number of tokens\n",
    "\n",
    "len(annotator1_toks)\n",
    "len(annotator2_toks) # Should match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 11537, False: 58})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare each item in each list to check if match\n",
    "\n",
    "annotator_match = [i==j for i, j in zip(annotator1_toks, annotator2_toks)]\n",
    "Counter(annotator_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of matching tokens:  99.5\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of matching tokens: ', round(Counter(annotator_match)[1]/len(annotator1_toks)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(Counter(annotator_match)[1]/len(annotator1_toks)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 99.5% agreement rate between annotators indicates high inter-rater reliability. The 58 mismatches will be adjudicated by a third annotator to produce one final version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotator 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe for annotator3 with 'checked' column removed\n",
    "\n",
    "annotator3_df = annotator1_df.iloc[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tok_lem_POS_corrected</th>\n",
       "      <th>enumerated_unchecked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23739</th>\n",
       "      <td>I was sleeping when my cell phone rang. Then I...</td>\n",
       "      <td>[I, was, sleeping, when, my, cell, phone, rang...</td>\n",
       "      <td>[(i, i, PRP), (was, be, VBD), (sleeping, sleep...</td>\n",
       "      <td>[(0, I), (1, was), (2, sleeping), (3, when), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23488</th>\n",
       "      <td>I had an experience that taught me intuitive d...</td>\n",
       "      <td>[I, had, an, experience, that, taught, me, int...</td>\n",
       "      <td>[(i, i, PRP), (had, have, VBD), (an, a, DT), (...</td>\n",
       "      <td>[(0, I), (1, had), (2, an), (3, experience), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text  \\\n",
       "answer_id                                                      \n",
       "23739      I was sleeping when my cell phone rang. Then I...   \n",
       "23488      I had an experience that taught me intuitive d...   \n",
       "\n",
       "                                                      tokens  \\\n",
       "answer_id                                                      \n",
       "23739      [I, was, sleeping, when, my, cell, phone, rang...   \n",
       "23488      [I, had, an, experience, that, taught, me, int...   \n",
       "\n",
       "                                       tok_lem_POS_corrected  \\\n",
       "answer_id                                                      \n",
       "23739      [(i, i, PRP), (was, be, VBD), (sleeping, sleep...   \n",
       "23488      [(i, i, PRP), (had, have, VBD), (an, a, DT), (...   \n",
       "\n",
       "                                        enumerated_unchecked  \n",
       "answer_id                                                     \n",
       "23739      [(0, I), (1, was), (2, sleeping), (3, when), (...  \n",
       "23488      [(0, I), (1, had), (2, an), (3, experience), (...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a column with enumerated unchecked texts\n",
    "\n",
    "annotator3_df['enumerated_unchecked'] = annotator3_df.tokens.apply(enumerate).apply(list)\n",
    "annotator3_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of original enumerated tokens\n",
    "\n",
    "original_toks = [x for y in annotator3_df.enumerated_unchecked.to_list() for x in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[((48, 'craigslist'), (48, 'craiglist'), (48, 'craiglist')),\n",
       " ((191, 'am'), (191, 'a.m'), (191, 'a.m')),\n",
       " ((99, 'experience'), (99, 'expierience'), (99, 'expierience')),\n",
       " ((19, 'the'), (19, 'te'), (19, 'te')),\n",
       " ((50, 'sightseeing'), (50, 'sight-seeing'), (50, 'sigthseeing'))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of enumerated mismatches\n",
    "\n",
    "mismatches = [(i,j,k) for (i,j,k) in zip(annotator1_toks, annotator2_toks, original_toks) if i!=j]\n",
    "len(mismatches)\n",
    "len(set(mismatches))\n",
    "mismatches[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "61.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create flat list of all mistmatch items\n",
    "\n",
    "flat_mismatches = [x for y in mismatches for x in y]\n",
    "len(flat_mismatches) # 58*3\n",
    "flat_mismatches = set(flat_mismatches)\n",
    "len(flat_mismatches) # After duplicates removed\n",
    "len(flat_mismatches)/2 # unique items to adjudicate\n",
    "\n",
    "# This list is three items longer than the previous as (19, 'the') occurs in three texts and (18, 'since') occurs in two texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tok_lem_POS_corrected</th>\n",
       "      <th>enumerated_unchecked</th>\n",
       "      <th>to_check</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23739</th>\n",
       "      <td>I was sleeping when my cell phone rang. Then I...</td>\n",
       "      <td>[I, was, sleeping, when, my, cell, phone, rang...</td>\n",
       "      <td>[(i, i, PRP), (was, be, VBD), (sleeping, sleep...</td>\n",
       "      <td>[(0, I), (1, was), (2, sleeping), (3, when), (...</td>\n",
       "      <td>[(48, craiglist), (191, a.m)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38157</th>\n",
       "      <td>Traveling makes me happy. I am really like to ...</td>\n",
       "      <td>[Traveling, makes, me, happy, ., I, am, really...</td>\n",
       "      <td>[(traveling, travel, VBG), (makes, make, VBZ),...</td>\n",
       "      <td>[(0, Traveling), (1, makes), (2, me), (3, happ...</td>\n",
       "      <td>[(19, the), (99, expierience)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10494</th>\n",
       "      <td>Indonesia \\n \\n It is a piece of the paradiece...</td>\n",
       "      <td>[Indonesia, It, is, a, piece, of, the, paradie...</td>\n",
       "      <td>[(indonesia, indonesia, NN), (it, it, PRP), (i...</td>\n",
       "      <td>[(0, Indonesia), (1, It), (2, is), (3, a), (4,...</td>\n",
       "      <td>[(19, te), (50, sigthseeing)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47714</th>\n",
       "      <td>Terrible Weekend\\n Last weekend was a terribl...</td>\n",
       "      <td>[Terrible, Weekend, Last, weekend, was, a, ter...</td>\n",
       "      <td>[(terrible, terrible, JJ), (weekend, weekend, ...</td>\n",
       "      <td>[(0, Terrible), (1, Weekend), (2, Last), (3, w...</td>\n",
       "      <td>[(48, shouid), (58, Idecided), (168, tidous)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28804</th>\n",
       "      <td>The article \"Reponsibility and learning\" base...</td>\n",
       "      <td>[The, article, ``, Reponsibility, and, learnin...</td>\n",
       "      <td>[(the, the, DT), (article, article, NN), (``, ...</td>\n",
       "      <td>[(0, The), (1, article), (2, ``), (3, Reponsib...</td>\n",
       "      <td>[(3, Reponsibility), (50, towords), (115, writ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text  \\\n",
       "answer_id                                                      \n",
       "23739      I was sleeping when my cell phone rang. Then I...   \n",
       "38157      Traveling makes me happy. I am really like to ...   \n",
       "10494      Indonesia \\n \\n It is a piece of the paradiece...   \n",
       "47714       Terrible Weekend\\n Last weekend was a terribl...   \n",
       "28804       The article \"Reponsibility and learning\" base...   \n",
       "\n",
       "                                                      tokens  \\\n",
       "answer_id                                                      \n",
       "23739      [I, was, sleeping, when, my, cell, phone, rang...   \n",
       "38157      [Traveling, makes, me, happy, ., I, am, really...   \n",
       "10494      [Indonesia, It, is, a, piece, of, the, paradie...   \n",
       "47714      [Terrible, Weekend, Last, weekend, was, a, ter...   \n",
       "28804      [The, article, ``, Reponsibility, and, learnin...   \n",
       "\n",
       "                                       tok_lem_POS_corrected  \\\n",
       "answer_id                                                      \n",
       "23739      [(i, i, PRP), (was, be, VBD), (sleeping, sleep...   \n",
       "38157      [(traveling, travel, VBG), (makes, make, VBZ),...   \n",
       "10494      [(indonesia, indonesia, NN), (it, it, PRP), (i...   \n",
       "47714      [(terrible, terrible, JJ), (weekend, weekend, ...   \n",
       "28804      [(the, the, DT), (article, article, NN), (``, ...   \n",
       "\n",
       "                                        enumerated_unchecked  \\\n",
       "answer_id                                                      \n",
       "23739      [(0, I), (1, was), (2, sleeping), (3, when), (...   \n",
       "38157      [(0, Traveling), (1, makes), (2, me), (3, happ...   \n",
       "10494      [(0, Indonesia), (1, It), (2, is), (3, a), (4,...   \n",
       "47714      [(0, Terrible), (1, Weekend), (2, Last), (3, w...   \n",
       "28804      [(0, The), (1, article), (2, ``), (3, Reponsib...   \n",
       "\n",
       "                                                    to_check  \n",
       "answer_id                                                     \n",
       "23739                          [(48, craiglist), (191, a.m)]  \n",
       "38157                         [(19, the), (99, expierience)]  \n",
       "10494                          [(19, te), (50, sigthseeing)]  \n",
       "47714          [(48, shouid), (58, Idecided), (168, tidous)]  \n",
       "28804      [(3, Reponsibility), (50, towords), (115, writ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create column of items to adjudicate based on inclusion in mismatches\n",
    "\n",
    "annotator3_df['to_check'] = annotator3_df.enumerated_unchecked.apply(lambda row: [x for x in row if x in flat_mismatches])\n",
    "annotator3_df.loc[(annotator3_df.to_check.str.len() != 0),:].head() # Check rows with non-empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check number of mismatches\n",
    "\n",
    "to_check = [x for y in annotator3_df.loc[(annotator3_df.to_check.str.len() != 0),:].to_check.to_list() for x in y]\n",
    "len(to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out csv for annotator3\n",
    "\n",
    "annotator3_df.to_csv('annotator3_blank.csv', encoding='utf-8', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tok_lem_POS_corrected</th>\n",
       "      <th>enumerated_unchecked</th>\n",
       "      <th>to_check</th>\n",
       "      <th>enumerated_checked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23739</th>\n",
       "      <td>I was sleeping when my cell phone rang. Then I...</td>\n",
       "      <td>[I, was, sleeping, when, my, cell, phone, rang...</td>\n",
       "      <td>[(i, i, PRP), (was, be, VBD), (sleeping, sleep...</td>\n",
       "      <td>[(0, 'I'), (1, 'was'), (2, 'sleeping'), (3, 'w...</td>\n",
       "      <td>[(48, 'craiglist'), (191, 'a.m')]</td>\n",
       "      <td>[(0, I), (1, was), (2, sleeping), (3, when), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23488</th>\n",
       "      <td>I had an experience that taught me intuitive d...</td>\n",
       "      <td>[I, had, an, experience, that, taught, me, int...</td>\n",
       "      <td>[(i, i, PRP), (had, have, VBD), (an, a, DT), (...</td>\n",
       "      <td>[(0, 'I'), (1, 'had'), (2, 'an'), (3, 'experie...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(0, I), (1, had), (2, an), (3, experience), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text  \\\n",
       "answer_id                                                      \n",
       "23739      I was sleeping when my cell phone rang. Then I...   \n",
       "23488      I had an experience that taught me intuitive d...   \n",
       "\n",
       "                                                      tokens  \\\n",
       "answer_id                                                      \n",
       "23739      [I, was, sleeping, when, my, cell, phone, rang...   \n",
       "23488      [I, had, an, experience, that, taught, me, int...   \n",
       "\n",
       "                                       tok_lem_POS_corrected  \\\n",
       "answer_id                                                      \n",
       "23739      [(i, i, PRP), (was, be, VBD), (sleeping, sleep...   \n",
       "23488      [(i, i, PRP), (had, have, VBD), (an, a, DT), (...   \n",
       "\n",
       "                                        enumerated_unchecked  \\\n",
       "answer_id                                                      \n",
       "23739      [(0, 'I'), (1, 'was'), (2, 'sleeping'), (3, 'w...   \n",
       "23488      [(0, 'I'), (1, 'had'), (2, 'an'), (3, 'experie...   \n",
       "\n",
       "                                    to_check  \\\n",
       "answer_id                                      \n",
       "23739      [(48, 'craiglist'), (191, 'a.m')]   \n",
       "23488                                     []   \n",
       "\n",
       "                                          enumerated_checked  \n",
       "answer_id                                                     \n",
       "23739      [(0, I), (1, was), (2, sleeping), (3, when), (...  \n",
       "23488      [(0, I), (1, had), (2, an), (3, experience), (...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in checked annotator3 csv\n",
    "\n",
    "final_df = pd.read_csv(\"annotator3_checked.csv\", index_col = 'answer_id',\n",
    "                            converters={'tokens':literal_eval,'tok_lem_POS_corrected':literal_eval,\n",
    "                                        'enumerated':literal_eval, 'enumerated_checked':literal_eval})\n",
    "\n",
    "final_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lower-cased version of enumerated_checked with only the tokens (to match tok_lem_POS_corrected column)\n",
    "\n",
    "final_df['human_checked'] = final_df.enumerated_checked.apply(lambda row: [x[1].lower() for x in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>automated_checked</th>\n",
       "      <th>human_checked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23739</th>\n",
       "      <td>[i, was, sleeping, when, my, cell, phone, rang...</td>\n",
       "      <td>[i, was, sleeping, when, my, cell, phone, rang...</td>\n",
       "      <td>[i, was, sleeping, when, my, cell, phone, rang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23488</th>\n",
       "      <td>[i, had, an, experience, that, taught, me, int...</td>\n",
       "      <td>[i, had, an, experience, that, taught, me, int...</td>\n",
       "      <td>[i, had, an, experience, that, taught, me, int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16214</th>\n",
       "      <td>[the, most, interesting, experience, i, have, ...</td>\n",
       "      <td>[the, most, interesting, experience, i, have, ...</td>\n",
       "      <td>[the, most, interesting, experience, i, have, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11926</th>\n",
       "      <td>[when, i, was, a, five, years, old, ., i, had,...</td>\n",
       "      <td>[when, i, was, a, five, years, old, ., i, had,...</td>\n",
       "      <td>[when, i, was, a, five, years, old, ., i, had,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38157</th>\n",
       "      <td>[traveling, makes, me, happy, ., i, am, really...</td>\n",
       "      <td>[traveling, makes, me, happy, ., i, am, really...</td>\n",
       "      <td>[traveling, makes, me, happy, ., i, am, really...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    original  \\\n",
       "answer_id                                                      \n",
       "23739      [i, was, sleeping, when, my, cell, phone, rang...   \n",
       "23488      [i, had, an, experience, that, taught, me, int...   \n",
       "16214      [the, most, interesting, experience, i, have, ...   \n",
       "11926      [when, i, was, a, five, years, old, ., i, had,...   \n",
       "38157      [traveling, makes, me, happy, ., i, am, really...   \n",
       "\n",
       "                                           automated_checked  \\\n",
       "answer_id                                                      \n",
       "23739      [i, was, sleeping, when, my, cell, phone, rang...   \n",
       "23488      [i, had, an, experience, that, taught, me, int...   \n",
       "16214      [the, most, interesting, experience, i, have, ...   \n",
       "11926      [when, i, was, a, five, years, old, ., i, had,...   \n",
       "38157      [traveling, makes, me, happy, ., i, am, really...   \n",
       "\n",
       "                                               human_checked  \n",
       "answer_id                                                     \n",
       "23739      [i, was, sleeping, when, my, cell, phone, rang...  \n",
       "23488      [i, had, an, experience, that, taught, me, int...  \n",
       "16214      [the, most, interesting, experience, i, have, ...  \n",
       "11926      [when, i, was, a, five, years, old, ., i, had,...  \n",
       "38157      [traveling, makes, me, happy, ., i, am, really...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up dataframe for easier analysis\n",
    "\n",
    "final_df = final_df[['tokens','tok_lem_POS_corrected','human_checked']]\n",
    "final_df = final_df.rename(columns={\"tokens\": \"original\", \"tok_lem_POS_corrected\": \"automated_checked\"})\n",
    "final_df['automated_checked'] = final_df.automated_checked.apply(lambda row: [x[0] for x in row])\n",
    "final_df['original'] = final_df.original.apply(lambda row: [x.lower() for x in row])\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Spell check comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing the tokens, from the three columns, there are five total possibilities:\n",
    "1. The original token was not misspelled and the spell checker recognized this. In this case, we would expect all three tokens to be equal to one another.\n",
    "2. The original token was misspelled and the spell checker corrected it. In this case, we would expect *automated_checked* and *human_checked* to be equal, with *original* being the outlier.\n",
    "3. The original token was misspelled but the spell checker did not recognize this. In this case, *original* and *automated_checked* would be equal, but neither would be equal to the correct spelling of *human_checked*. This would be a Type II error, i.e., a false negative.\n",
    "4. None of the three columns are equal to one another. This means that there was a misspelling, but the automated check was wrong (as judged by the human checker).\n",
    "5. The original token was spelled correctly, but the spellchecker still applied a correction to it. In this case, *original* and *human_checked* would be equal to one another, with *automated_checked* being a mismatch. This is a Type I error, i.e., a false positive.\n",
    "\n",
    "We now create methods that use *if* statements to check each of these cases. The methods function the same way: they simply parse through the lists, and when a condition is met, it adds the token to a list. The list is then returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating functions for each case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'a', 'a', 'a')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_none(l1, l2, l3):\n",
    "    \"\"\"Returns the number of correct spellings in a token set where l1 is the\n",
    "    original token list, l2 is the automated_checked list, and l3 is the human_checked list\"\"\"\n",
    "    l0 = []\n",
    "    ref = list(enumerate(l1))\n",
    "    for i in range(len(l1)):\n",
    "        if l1[i] == l3[i] and l2[i] == l3[i]:\n",
    "            l0.append((ref[i][0], l1[i], l2[i], l3[i]))\n",
    "    return l0\n",
    "\n",
    "l1 = ['a', 'f', 'f', 'f', 'e']\n",
    "l2 = ['a', 'b', 'f', 'g', 'f']\n",
    "l3 = ['a', 'b', 'c', 'd', 'e']\n",
    "get_none(l1, l2, l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'f', 'b', 'b')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_correct(l1, l2, l3):\n",
    "    \"\"\"Returns the number of corrected misspellings in a token set where l1 is the\n",
    "    original token list, l2 is the automated_checked list, and l3 is the human_checked list\"\"\"\n",
    "    l0 = []\n",
    "    ref = list(enumerate(l1))\n",
    "    for i in range(len(l1)):\n",
    "        if l1[i] != l3[i] and l2[i] == l3[i]:\n",
    "            l0.append((ref[i][0], l1[i], l2[i], l3[i]))\n",
    "    return l0\n",
    "\n",
    "get_correct(l1, l2, l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'f', 'f', 'c')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_false_neg(l1, l2, l3):\n",
    "    \"\"\"Returns the number of false negatives in a token set where l1 is the\n",
    "    original token list, l2 is the automated_checked list, and l3 is the human_checked list\"\"\"\n",
    "    l0 = []\n",
    "    ref = list(enumerate(l1))\n",
    "    for i in range(len(l1)):\n",
    "        if l1[i] != l3[i] and l2[i] != l3[i] and l1[i] == l2[i]:\n",
    "            l0.append((ref[i][0], l1[i], l2[i], l3[i]))\n",
    "    return l0\n",
    "\n",
    "get_false_neg(l1, l2, l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 'f', 'g', 'd')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_incorrect(l1, l2, l3):\n",
    "    \"\"\"Returns the number of false negatives in a token set where l1 is the\n",
    "    original token list, l2 is the automated_checked list, and l3 is the human_checked list\"\"\"\n",
    "    l0 = []\n",
    "    ref = list(enumerate(l1))\n",
    "    for i in range(len(l1)):\n",
    "        if l1[i] != l3[i] and l2[i] != l3[i] and l1[i] != l2[i]:\n",
    "            l0.append((ref[i][0], l1[i], l2[i], l3[i]))\n",
    "    return l0\n",
    "\n",
    "get_incorrect(l1, l2, l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 'e', 'f', 'e')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_false_pos(l1, l2, l3):\n",
    "    \"\"\"Returns the number of false negatives in a token set where l1 is the\n",
    "    original token list, l2 is the automated_checked list, and l3 is the human_checked list\"\"\"\n",
    "    l0 = []\n",
    "    ref = list(enumerate(l1))\n",
    "    for i in range(len(l1)):\n",
    "        if l1[i] == l3[i] and l2[i] != l3[i]:\n",
    "            l0.append((ref[i][0], l1[i], l2[i], l3[i]))\n",
    "    return l0\n",
    "\n",
    "get_false_pos(l1, l2, l3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying methods to final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function list.append(object, /)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[].append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>automated_checked</th>\n",
       "      <th>human_checked</th>\n",
       "      <th>true_negatives</th>\n",
       "      <th>true_positives</th>\n",
       "      <th>false_negatives</th>\n",
       "      <th>true_positives_incorrect</th>\n",
       "      <th>false_positives</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23739</th>\n",
       "      <td>[i, was, sleeping, when, my, cell, phone, rang...</td>\n",
       "      <td>[i, was, sleeping, when, my, cell, phone, rang...</td>\n",
       "      <td>[i, was, sleeping, when, my, cell, phone, rang...</td>\n",
       "      <td>[(0, i, i, i), (1, was, was, was), (2, sleepin...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(191, a.m, a.m, a.m.)]</td>\n",
       "      <td>[(48, craiglist, craig list, craigslist)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23488</th>\n",
       "      <td>[i, had, an, experience, that, taught, me, int...</td>\n",
       "      <td>[i, had, an, experience, that, taught, me, int...</td>\n",
       "      <td>[i, had, an, experience, that, taught, me, int...</td>\n",
       "      <td>[(0, i, i, i), (1, had, had, had), (2, an, an,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(8, decition, decision, decition), (95, liein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16214</th>\n",
       "      <td>[the, most, interesting, experience, i, have, ...</td>\n",
       "      <td>[the, most, interesting, experience, i, have, ...</td>\n",
       "      <td>[the, most, interesting, experience, i, have, ...</td>\n",
       "      <td>[(0, the, the, the), (1, most, most, most), (2...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(20, merridian, meridian, merridian)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11926</th>\n",
       "      <td>[when, i, was, a, five, years, old, ., i, had,...</td>\n",
       "      <td>[when, i, was, a, five, years, old, ., i, had,...</td>\n",
       "      <td>[when, i, was, a, five, years, old, ., i, had,...</td>\n",
       "      <td>[(0, when, when, when), (1, i, i, i), (2, was,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(97, charecter, character, charecter), (103, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38157</th>\n",
       "      <td>[traveling, makes, me, happy, ., i, am, really...</td>\n",
       "      <td>[traveling, makes, me, happy, ., i, am, really...</td>\n",
       "      <td>[traveling, makes, me, happy, ., i, am, really...</td>\n",
       "      <td>[(0, traveling, traveling, traveling), (1, mak...</td>\n",
       "      <td>[(99, expierience, experience, experience)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(79, underware, under are, underware)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    original  \\\n",
       "answer_id                                                      \n",
       "23739      [i, was, sleeping, when, my, cell, phone, rang...   \n",
       "23488      [i, had, an, experience, that, taught, me, int...   \n",
       "16214      [the, most, interesting, experience, i, have, ...   \n",
       "11926      [when, i, was, a, five, years, old, ., i, had,...   \n",
       "38157      [traveling, makes, me, happy, ., i, am, really...   \n",
       "\n",
       "                                           automated_checked  \\\n",
       "answer_id                                                      \n",
       "23739      [i, was, sleeping, when, my, cell, phone, rang...   \n",
       "23488      [i, had, an, experience, that, taught, me, int...   \n",
       "16214      [the, most, interesting, experience, i, have, ...   \n",
       "11926      [when, i, was, a, five, years, old, ., i, had,...   \n",
       "38157      [traveling, makes, me, happy, ., i, am, really...   \n",
       "\n",
       "                                               human_checked  \\\n",
       "answer_id                                                      \n",
       "23739      [i, was, sleeping, when, my, cell, phone, rang...   \n",
       "23488      [i, had, an, experience, that, taught, me, int...   \n",
       "16214      [the, most, interesting, experience, i, have, ...   \n",
       "11926      [when, i, was, a, five, years, old, ., i, had,...   \n",
       "38157      [traveling, makes, me, happy, ., i, am, really...   \n",
       "\n",
       "                                              true_negatives  \\\n",
       "answer_id                                                      \n",
       "23739      [(0, i, i, i), (1, was, was, was), (2, sleepin...   \n",
       "23488      [(0, i, i, i), (1, had, had, had), (2, an, an,...   \n",
       "16214      [(0, the, the, the), (1, most, most, most), (2...   \n",
       "11926      [(0, when, when, when), (1, i, i, i), (2, was,...   \n",
       "38157      [(0, traveling, traveling, traveling), (1, mak...   \n",
       "\n",
       "                                        true_positives  \\\n",
       "answer_id                                                \n",
       "23739                                               []   \n",
       "23488                                               []   \n",
       "16214                                               []   \n",
       "11926                                               []   \n",
       "38157      [(99, expierience, experience, experience)]   \n",
       "\n",
       "                   false_negatives                   true_positives_incorrect  \\\n",
       "answer_id                                                                       \n",
       "23739      [(191, a.m, a.m, a.m.)]  [(48, craiglist, craig list, craigslist)]   \n",
       "23488                           []                                         []   \n",
       "16214                           []                                         []   \n",
       "11926                           []                                         []   \n",
       "38157                           []                                         []   \n",
       "\n",
       "                                             false_positives  \n",
       "answer_id                                                     \n",
       "23739                                                     []  \n",
       "23488      [(8, decition, decision, decition), (95, liein...  \n",
       "16214                 [(20, merridian, meridian, merridian)]  \n",
       "11926      [(97, charecter, character, charecter), (103, ...  \n",
       "38157                [(79, underware, under are, underware)]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "none = []\n",
    "correct = []\n",
    "neg = []\n",
    "incorrect = []\n",
    "pos = []\n",
    "\n",
    "for i in range(50):\n",
    "    row = final_df.iloc[i]\n",
    "    none.append(get_none(row[0], row[1], row[2]))\n",
    "    correct.append(get_correct(row[0], row[1], row[2]))\n",
    "    neg.append(get_false_neg(row[0], row[1], row[2]))\n",
    "    incorrect.append(get_incorrect(row[0], row[1], row[2]))\n",
    "    pos.append(get_false_pos(row[0], row[1], row[2]))\n",
    "\n",
    "final_df['true_negatives'] = pd.Series(none).values\n",
    "final_df['true_positives'] = pd.Series(correct).values\n",
    "final_df['false_negatives'] = pd.Series(neg).values\n",
    "final_df['true_positives_incorrect'] = pd.Series(incorrect).values\n",
    "final_df['false_positives'] = pd.Series(pos).values\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>automated_checked</th>\n",
       "      <th>human_checked</th>\n",
       "      <th>true_negatives</th>\n",
       "      <th>true_positives</th>\n",
       "      <th>false_negatives</th>\n",
       "      <th>true_positives_incorrect</th>\n",
       "      <th>false_positives</th>\n",
       "      <th>true_negatives_count</th>\n",
       "      <th>true_positives_count</th>\n",
       "      <th>false_negatives_count</th>\n",
       "      <th>true_positives_incorrect_count</th>\n",
       "      <th>false_positives_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23739</th>\n",
       "      <td>[i, was, sleeping, when, my, cell, phone, rang...</td>\n",
       "      <td>[i, was, sleeping, when, my, cell, phone, rang...</td>\n",
       "      <td>[i, was, sleeping, when, my, cell, phone, rang...</td>\n",
       "      <td>[(0, i, i, i), (1, was, was, was), (2, sleepin...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(191, a.m, a.m, a.m.)]</td>\n",
       "      <td>[(48, craiglist, craig list, craigslist)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>375</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23488</th>\n",
       "      <td>[i, had, an, experience, that, taught, me, int...</td>\n",
       "      <td>[i, had, an, experience, that, taught, me, int...</td>\n",
       "      <td>[i, had, an, experience, that, taught, me, int...</td>\n",
       "      <td>[(0, i, i, i), (1, had, had, had), (2, an, an,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(8, decition, decision, decition), (95, liein...</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16214</th>\n",
       "      <td>[the, most, interesting, experience, i, have, ...</td>\n",
       "      <td>[the, most, interesting, experience, i, have, ...</td>\n",
       "      <td>[the, most, interesting, experience, i, have, ...</td>\n",
       "      <td>[(0, the, the, the), (1, most, most, most), (2...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(20, merridian, meridian, merridian)]</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11926</th>\n",
       "      <td>[when, i, was, a, five, years, old, ., i, had,...</td>\n",
       "      <td>[when, i, was, a, five, years, old, ., i, had,...</td>\n",
       "      <td>[when, i, was, a, five, years, old, ., i, had,...</td>\n",
       "      <td>[(0, when, when, when), (1, i, i, i), (2, was,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(97, charecter, character, charecter), (103, ...</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38157</th>\n",
       "      <td>[traveling, makes, me, happy, ., i, am, really...</td>\n",
       "      <td>[traveling, makes, me, happy, ., i, am, really...</td>\n",
       "      <td>[traveling, makes, me, happy, ., i, am, really...</td>\n",
       "      <td>[(0, traveling, traveling, traveling), (1, mak...</td>\n",
       "      <td>[(99, expierience, experience, experience)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(79, underware, under are, underware)]</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    original  \\\n",
       "answer_id                                                      \n",
       "23739      [i, was, sleeping, when, my, cell, phone, rang...   \n",
       "23488      [i, had, an, experience, that, taught, me, int...   \n",
       "16214      [the, most, interesting, experience, i, have, ...   \n",
       "11926      [when, i, was, a, five, years, old, ., i, had,...   \n",
       "38157      [traveling, makes, me, happy, ., i, am, really...   \n",
       "\n",
       "                                           automated_checked  \\\n",
       "answer_id                                                      \n",
       "23739      [i, was, sleeping, when, my, cell, phone, rang...   \n",
       "23488      [i, had, an, experience, that, taught, me, int...   \n",
       "16214      [the, most, interesting, experience, i, have, ...   \n",
       "11926      [when, i, was, a, five, years, old, ., i, had,...   \n",
       "38157      [traveling, makes, me, happy, ., i, am, really...   \n",
       "\n",
       "                                               human_checked  \\\n",
       "answer_id                                                      \n",
       "23739      [i, was, sleeping, when, my, cell, phone, rang...   \n",
       "23488      [i, had, an, experience, that, taught, me, int...   \n",
       "16214      [the, most, interesting, experience, i, have, ...   \n",
       "11926      [when, i, was, a, five, years, old, ., i, had,...   \n",
       "38157      [traveling, makes, me, happy, ., i, am, really...   \n",
       "\n",
       "                                              true_negatives  \\\n",
       "answer_id                                                      \n",
       "23739      [(0, i, i, i), (1, was, was, was), (2, sleepin...   \n",
       "23488      [(0, i, i, i), (1, had, had, had), (2, an, an,...   \n",
       "16214      [(0, the, the, the), (1, most, most, most), (2...   \n",
       "11926      [(0, when, when, when), (1, i, i, i), (2, was,...   \n",
       "38157      [(0, traveling, traveling, traveling), (1, mak...   \n",
       "\n",
       "                                        true_positives  \\\n",
       "answer_id                                                \n",
       "23739                                               []   \n",
       "23488                                               []   \n",
       "16214                                               []   \n",
       "11926                                               []   \n",
       "38157      [(99, expierience, experience, experience)]   \n",
       "\n",
       "                   false_negatives                   true_positives_incorrect  \\\n",
       "answer_id                                                                       \n",
       "23739      [(191, a.m, a.m, a.m.)]  [(48, craiglist, craig list, craigslist)]   \n",
       "23488                           []                                         []   \n",
       "16214                           []                                         []   \n",
       "11926                           []                                         []   \n",
       "38157                           []                                         []   \n",
       "\n",
       "                                             false_positives  \\\n",
       "answer_id                                                      \n",
       "23739                                                     []   \n",
       "23488      [(8, decition, decision, decition), (95, liein...   \n",
       "16214                 [(20, merridian, meridian, merridian)]   \n",
       "11926      [(97, charecter, character, charecter), (103, ...   \n",
       "38157                [(79, underware, under are, underware)]   \n",
       "\n",
       "           true_negatives_count  true_positives_count  false_negatives_count  \\\n",
       "answer_id                                                                      \n",
       "23739                       375                     0                      1   \n",
       "23488                       180                     0                      0   \n",
       "16214                       181                     0                      0   \n",
       "11926                       135                     0                      0   \n",
       "38157                       137                     1                      0   \n",
       "\n",
       "           true_positives_incorrect_count  false_positives_count  \n",
       "answer_id                                                         \n",
       "23739                                   1                      0  \n",
       "23488                                   0                      2  \n",
       "16214                                   0                      1  \n",
       "11926                                   0                      2  \n",
       "38157                                   0                      1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['true_negatives_count'] = final_df.true_negatives.map(lambda x: len(x))\n",
    "final_df['true_positives_count'] = final_df.true_positives.map(lambda x: len(x))\n",
    "final_df['false_negatives_count'] = final_df.false_negatives.map(lambda x: len(x))\n",
    "final_df['true_positives_incorrect_count'] = final_df.true_positives_incorrect.map(lambda x: len(x))\n",
    "final_df['false_positives_count'] = final_df.false_positives.map(lambda x: len(x))\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data analysis\n",
    "To judge the effectiveness of the automated checker, we calculate accuracy, precision, recall, and the F-measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 11458\n",
      "True Positives: 21\n",
      "Incorrect True Positives: 7      \n",
      "False Negatives: 9\n",
      "False Positives: 100\n",
      "\n",
      "Accuracy:  0.99\n",
      "Precision:  0.17\n",
      "Recall:  0.7\n",
      "F-Measure 0.27\n"
     ]
    }
   ],
   "source": [
    "true_neg = final_df[\"true_negatives_count\"].sum()\n",
    "true_pos = final_df[\"true_positives_count\"].sum()\n",
    "true_pos_incorrect = final_df[\"true_positives_incorrect_count\"].sum()\n",
    "false_neg = final_df[\"false_negatives_count\"].sum()\n",
    "false_pos = final_df[\"false_positives_count\"].sum()\n",
    "print(f\"True Negatives: {true_neg}\\nTrue Positives: {true_pos}\\nIncorrect True Positives: {true_pos_incorrect}\\\n",
    "      \\nFalse Negatives: {false_neg}\\nFalse Positives: {false_pos}\\n\")\n",
    "\n",
    "accuracy = round((true_neg + true_pos)/(true_neg + true_pos + false_neg + false_pos),2)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "precision = round(true_pos /(true_pos + false_pos),2)\n",
    "print(\"Precision: \", precision)\n",
    "recall = round(true_pos / (true_pos + false_neg),2)\n",
    "print(\"Recall: \", recall)\n",
    "f = round((2 * precision * recall)/(precision + recall),2)\n",
    "print(\"F-Measure\", f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "We set out with the intent to see how well our spellchecking tool corrects ESL data. So how does it do?<br>\n",
    "It does fairly well, performing very accurately but not nearly as precisely.\n",
    "\n",
    "**Accuracy, Precision and Recall**\n",
    "\n",
    "The spellchecker has two main measures of performance. First, accuracy measures how well the spellchecker performs at correcting words. This score is comprised by looking at the correction the spellchecker provides. For example, in the case where the word is correctly spelled and the spellchecker does nothing, the accuracy is 1/1.\n",
    "\n",
    "On the other hand, we have the measures of binary classification: precision, recall, and F-measure. These statistics show how well the spellchecker performs as a classifier of spelling error, that is, how complete is the spellchecker's coverage of misspelled words? Does it overstate the set of misspelled words? Does it underestimate them? We answer these questions empirically with the word-level statistics of true positives, true negatives, false positives, and false negatives. We then use the proportions of these tags to calculate the precision, recall, and F-measure. In our case, precision represents the proportion of words tagged as incorrect that were actually incorrect (i.e. if the classifier corrected \"don't\" to \"donut\", it would lower precision). On the other hand, recall represents the proportion of words tagged as incorrect to the total set of incorrect words. Finally, the F-measure is a balance of precision and recall to give a fuller picture of performance.\n",
    "\n",
    "For more on classifier evaluation, we recommend [this article](https://www.svds.com/the-basics-of-classifier-evaluation-part-1/) by Tom Fawcett.\n",
    "\n",
    "**Performance**\n",
    "\n",
    "First, we see that the accuracy of the tool is very good. Both of the annotators found a >99% accuracy, meaning that over 99% of the spellchecker's output is spelled correctly. This is impressive as it means that the spell-corrected version of PELIC can be trusted to answer research questions. However, it is important to note that this figure represents the proportion of correctly spelled words, which would likely be very high even without a spellchecker (especially for more advanced students).  \n",
    "Moving on to precision and recall, we see a noticeable drop-off. The F-measure in this case tells us that our spell-checking classifier is quite robust (the recall) in terms of classifying errors from *all* of the tokens, but less precise when classifying errors from the smaller subset of tokens the humans tagged as errors. Overall, these figures indicate that the spell checking is conservative, leaving the data unchanged in many cases. This approach is prefered in the spirit of minimizing data manipulation and introduction of possible errors, though researchers may wish to apply further more fine-grained spelling correction depending upon their research needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Table-of-Contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
